{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROTOCOL_PATH = r\"C:\\Users\\Administrator\\Documents\\OrenTsurCourse\\knesset-analysis\\data\\knesset_protocols.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at avichr/heBERT_sentiment_analysis were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "c:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def add_sentiment(model, sent):\n",
    "    output = model(sent)\n",
    "    labels = [o['label'] for o in output]\n",
    "    return labels\n",
    "\n",
    "\n",
    "    # try:\n",
    "    #     return model(sent)[0]['label']\n",
    "    # except:\n",
    "    #     print(f\"sentence: {sent} is problematic\")\n",
    "    # return \"ERROR\"\n",
    "    # return 'TEST SENTIMENT'\n",
    "\n",
    "def load_model():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"avichr/heBERT_sentiment_analysis\") #same as 'avichr/heBERT' tokenizer\n",
    "    model = AutoModel.from_pretrained(\"avichr/heBERT_sentiment_analysis\")\n",
    "\n",
    "\n",
    "    # how to use?\n",
    "    sentiment_analysis = pipeline(\n",
    "        \"sentiment-analysis\",\n",
    "        model=\"avichr/heBERT_sentiment_analysis\",\n",
    "        tokenizer=\"avichr/heBERT_sentiment_analysis\",\n",
    "        return_all_scores = False\n",
    "    )\n",
    "    return sentiment_analysis\n",
    "\n",
    "model = load_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_sentiment(model, 'מלחמה')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.9995055198669434},\n",
       " {'label': 'negative', 'score': 0.9998195767402649}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['יום טוב', 'יום מזעזע']\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_id</th>\n",
       "      <th>committee_type</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>is_chairman</th>\n",
       "      <th>party_name</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>אלון טל</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>בוקר טוב לכולם, אני מתכבד לפתוח את הדיון הראשו...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>יוסף שיין</td>\n",
       "      <td>0</td>\n",
       "      <td>ישראל ביתנו</td>\n",
       "      <td>אדוני היושב-ראש, בוקר טוב, אני חושב שראוי להגד...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>אלון טל</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>בסדר, אומר לך איך אני רואה את זה באופן כללי וא...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>יוסף שיין</td>\n",
       "      <td>0</td>\n",
       "      <td>ישראל ביתנו</td>\n",
       "      <td>התקיימו ארבעה דיונים בנושא הזה, בדרך כלל אנחנו...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>אלון טל</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>היועצת המשפטית של הוועדה תיתן לנו את המסגרת המ...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>יוסף שיין</td>\n",
       "      <td>0</td>\n",
       "      <td>ישראל ביתנו</td>\n",
       "      <td>אשמח לשמוע את דעתה.</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>סימון דוידסון</td>\n",
       "      <td>0</td>\n",
       "      <td>יש עתיד</td>\n",
       "      <td>מילה אחת לפני, אדוני היושב-ראש, בירכנו את חברת...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>יוסף שיין</td>\n",
       "      <td>0</td>\n",
       "      <td>ישראל ביתנו</td>\n",
       "      <td>הקטגוריה של סבא וסבתא מקפיצה אותנו ברמה.</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>סימון דוידסון</td>\n",
       "      <td>0</td>\n",
       "      <td>יש עתיד</td>\n",
       "      <td>ראית איך הורדתי את הטונים שלו?</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>אמילי חיה מואטי</td>\n",
       "      <td>0</td>\n",
       "      <td>העבודה</td>\n",
       "      <td>אפשר לחזור ולדבר על רוסו.</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   protocol_id               committee_type        date             name  \\\n",
       "0          186  ועדת החינוך, התרבות והספורט  16/08/2022          אלון טל   \n",
       "1          186  ועדת החינוך, התרבות והספורט  16/08/2022        יוסף שיין   \n",
       "2          186  ועדת החינוך, התרבות והספורט  16/08/2022          אלון טל   \n",
       "3          186  ועדת החינוך, התרבות והספורט  16/08/2022        יוסף שיין   \n",
       "4          186  ועדת החינוך, התרבות והספורט  16/08/2022          אלון טל   \n",
       "5          186  ועדת החינוך, התרבות והספורט  16/08/2022        יוסף שיין   \n",
       "6          186  ועדת החינוך, התרבות והספורט  16/08/2022    סימון דוידסון   \n",
       "7          186  ועדת החינוך, התרבות והספורט  16/08/2022        יוסף שיין   \n",
       "8          186  ועדת החינוך, התרבות והספורט  16/08/2022    סימון דוידסון   \n",
       "9          186  ועדת החינוך, התרבות והספורט  16/08/2022  אמילי חיה מואטי   \n",
       "\n",
       "   is_chairman   party_name  \\\n",
       "0            1           -1   \n",
       "1            0  ישראל ביתנו   \n",
       "2            1           -1   \n",
       "3            0  ישראל ביתנו   \n",
       "4            1           -1   \n",
       "5            0  ישראל ביתנו   \n",
       "6            0      יש עתיד   \n",
       "7            0  ישראל ביתנו   \n",
       "8            0      יש עתיד   \n",
       "9            0       העבודה   \n",
       "\n",
       "                                                text sentiment  \n",
       "0  בוקר טוב לכולם, אני מתכבד לפתוח את הדיון הראשו...     ERROR  \n",
       "1  אדוני היושב-ראש, בוקר טוב, אני חושב שראוי להגד...     ERROR  \n",
       "2  בסדר, אומר לך איך אני רואה את זה באופן כללי וא...     ERROR  \n",
       "3  התקיימו ארבעה דיונים בנושא הזה, בדרך כלל אנחנו...     ERROR  \n",
       "4  היועצת המשפטית של הוועדה תיתן לנו את המסגרת המ...     ERROR  \n",
       "5                                אשמח לשמוע את דעתה.     ERROR  \n",
       "6  מילה אחת לפני, אדוני היושב-ראש, בירכנו את חברת...     ERROR  \n",
       "7           הקטגוריה של סבא וסבתא מקפיצה אותנו ברמה.     ERROR  \n",
       "8                     ראית איך הורדתי את הטונים שלו?     ERROR  \n",
       "9                          אפשר לחזור ולדבר על רוסו.     ERROR  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_debug = df[:10]\n",
    "df_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2468\n",
       "1     409\n",
       "2     274\n",
       "3     172\n",
       "4      52\n",
       "5      19\n",
       "6     160\n",
       "7      40\n",
       "8      30\n",
       "9      25\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_debug['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2468"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_debug['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.8377522826194763},\n",
       " {'label': 'positive', 'score': 0.9962816834449768},\n",
       " {'label': 'negative', 'score': 0.9997629523277283},\n",
       " {'label': 'positive', 'score': 0.9491382241249084},\n",
       " {'label': 'positive', 'score': 0.9858702421188354},\n",
       " {'label': 'positive', 'score': 0.999464213848114},\n",
       " {'label': 'positive', 'score': 0.9996922016143799},\n",
       " {'label': 'negative', 'score': 0.9957171082496643},\n",
       " {'label': 'negative', 'score': 0.9998735189437866},\n",
       " {'label': 'neutral', 'score': 0.9969620108604431}]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(list(df_debug['text'].apply(lambda s : s[:2048])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative', 'score': 0.8867250680923462},\n",
       " {'label': 'positive', 'score': 0.9962816834449768},\n",
       " {'label': 'negative', 'score': 0.9997629523277283},\n",
       " {'label': 'positive', 'score': 0.9491382241249084},\n",
       " {'label': 'positive', 'score': 0.9858702421188354},\n",
       " {'label': 'positive', 'score': 0.999464213848114},\n",
       " {'label': 'positive', 'score': 0.9996922016143799},\n",
       " {'label': 'negative', 'score': 0.9957171082496643},\n",
       " {'label': 'negative', 'score': 0.9998735189437866},\n",
       " {'label': 'neutral', 'score': 0.9969620108604431}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(list(df_debug['text'].apply(lambda s : s[:2048])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (581) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m add_sentiment(model, \u001b[39mlist\u001b[39;49m(df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m, in \u001b[0;36madd_sentiment\u001b[1;34m(model, sent)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_sentiment\u001b[39m(model, sent):\n\u001b[1;32m----> 2\u001b[0m     output \u001b[39m=\u001b[39m model(sent)\n\u001b[0;32m      3\u001b[0m     labels \u001b[39m=\u001b[39m [o[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m output]\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m labels\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:155\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    122\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39m        If `top_k` is used, one such dictionary is returned per label.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    156\u001b[0m     \u001b[39m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     _legacy \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtop_k\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\pipelines\\base.py:1100\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[39mif\u001b[39;00m can_use_iterator:\n\u001b[0;32m   1097\u001b[0m     final_iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_iterator(\n\u001b[0;32m   1098\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[0;32m   1099\u001b[0m     )\n\u001b[1;32m-> 1100\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(final_iterator)\n\u001b[0;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m outputs\n\u001b[0;32m   1102\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_item()\n\u001b[0;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator)\n\u001b[0;32m    125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m    124\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterator)\n\u001b[1;32m--> 125\u001b[0m processed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfer(item, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams)\n\u001b[0;32m    126\u001b[0m \u001b[39m# We now have a batch of \"inferred things\".\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[39m# Try to infer the size of the batch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\pipelines\\base.py:1025\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[39mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1024\u001b[0m         model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m-> 1025\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(model_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mforward_params)\n\u001b[0;32m   1026\u001b[0m         model_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   1027\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:182\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward\u001b[39m(\u001b[39mself\u001b[39m, model_inputs):\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1554\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1562\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert(\n\u001b[0;32m   1563\u001b[0m     input_ids,\n\u001b[0;32m   1564\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1565\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1566\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1567\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1568\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1569\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1570\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1571\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1572\u001b[0m )\n\u001b[0;32m   1574\u001b[0m pooled_output \u001b[39m=\u001b[39m outputs[\u001b[39m1\u001b[39m]\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[39m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[39m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m \u001b[39m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[39m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1013\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membeddings(\n\u001b[0;32m   1014\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1015\u001b[0m     position_ids\u001b[39m=\u001b[39;49mposition_ids,\n\u001b[0;32m   1016\u001b[0m     token_type_ids\u001b[39m=\u001b[39;49mtoken_type_ids,\n\u001b[0;32m   1017\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1018\u001b[0m     past_key_values_length\u001b[39m=\u001b[39;49mpast_key_values_length,\n\u001b[0;32m   1019\u001b[0m )\n\u001b[0;32m   1020\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(\n\u001b[0;32m   1021\u001b[0m     embedding_output,\n\u001b[0;32m   1022\u001b[0m     attention_mask\u001b[39m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1032\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\anaconda3\\envs\\knesset2\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:236\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    235\u001b[0m     position_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embeddings(position_ids)\n\u001b[1;32m--> 236\u001b[0m     embeddings \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m position_embeddings\n\u001b[0;32m    237\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLayerNorm(embeddings)\n\u001b[0;32m    238\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(embeddings)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (581) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "add_sentiment(model, list(df['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 0        בוקר טוב לכולם, אני מתכבד לפתוח את הדיון הראשו...\n",
      "1        אדוני היושב-ראש, בוקר טוב, אני חושב שראוי להגד...\n",
      "2        בסדר, אומר לך איך אני רואה את זה באופן כללי וא...\n",
      "3        התקיימו ארבעה דיונים בנושא הזה, בדרך כלל אנחנו...\n",
      "4        היועצת המשפטית של הוועדה תיתן לנו את המסגרת המ...\n",
      "                               ...                        \n",
      "37194    גם אני מברך אותך להתמנותך ליו\"ר הוועדה. אני חו...\n",
      "37195                                    תודה רבה. ח\"כ טל.\n",
      "37196    כבוד יושבת הראש אני באמת מצטרף למקהלת המברכים ...\n",
      "37197                   תודה רבה. בבקשה ח\"כ סימון דוידסון.\n",
      "37198    אני רוצה לברך אותך ומאוד שמחתי על מה שאמר רם ש...\n",
      "Name: text, Length: 37199, dtype: object is problematic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protocol_id</th>\n",
       "      <th>committee_type</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>is_chairman</th>\n",
       "      <th>party_name</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>אלון טל</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>בוקר טוב לכולם, אני מתכבד לפתוח את הדיון הראשו...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>יוסף שיין</td>\n",
       "      <td>0</td>\n",
       "      <td>ישראל ביתנו</td>\n",
       "      <td>אדוני היושב-ראש, בוקר טוב, אני חושב שראוי להגד...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>אלון טל</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>בסדר, אומר לך איך אני רואה את זה באופן כללי וא...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>יוסף שיין</td>\n",
       "      <td>0</td>\n",
       "      <td>ישראל ביתנו</td>\n",
       "      <td>התקיימו ארבעה דיונים בנושא הזה, בדרך כלל אנחנו...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>16/08/2022</td>\n",
       "      <td>אלון טל</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>היועצת המשפטית של הוועדה תיתן לנו את המסגרת המ...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37194</th>\n",
       "      <td>1</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>26/07/2021</td>\n",
       "      <td>משה טור פז</td>\n",
       "      <td>0</td>\n",
       "      <td>יש עתיד</td>\n",
       "      <td>גם אני מברך אותך להתמנותך ליו\"ר הוועדה. אני חו...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37195</th>\n",
       "      <td>1</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>26/07/2021</td>\n",
       "      <td>שרן מרים השכל</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>תודה רבה. ח\"כ טל.</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37196</th>\n",
       "      <td>1</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>26/07/2021</td>\n",
       "      <td>אלון טל</td>\n",
       "      <td>0</td>\n",
       "      <td>כחול לבן</td>\n",
       "      <td>כבוד יושבת הראש אני באמת מצטרף למקהלת המברכים ...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37197</th>\n",
       "      <td>1</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>26/07/2021</td>\n",
       "      <td>שרן מרים השכל</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>תודה רבה. בבקשה ח\"כ סימון דוידסון.</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37198</th>\n",
       "      <td>1</td>\n",
       "      <td>ועדת החינוך, התרבות והספורט</td>\n",
       "      <td>26/07/2021</td>\n",
       "      <td>סימון דוידסון</td>\n",
       "      <td>0</td>\n",
       "      <td>יש עתיד</td>\n",
       "      <td>אני רוצה לברך אותך ומאוד שמחתי על מה שאמר רם ש...</td>\n",
       "      <td>ERROR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37199 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       protocol_id               committee_type        date           name  \\\n",
       "0              186  ועדת החינוך, התרבות והספורט  16/08/2022        אלון טל   \n",
       "1              186  ועדת החינוך, התרבות והספורט  16/08/2022      יוסף שיין   \n",
       "2              186  ועדת החינוך, התרבות והספורט  16/08/2022        אלון טל   \n",
       "3              186  ועדת החינוך, התרבות והספורט  16/08/2022      יוסף שיין   \n",
       "4              186  ועדת החינוך, התרבות והספורט  16/08/2022        אלון טל   \n",
       "...            ...                          ...         ...            ...   \n",
       "37194            1  ועדת החינוך, התרבות והספורט  26/07/2021     משה טור פז   \n",
       "37195            1  ועדת החינוך, התרבות והספורט  26/07/2021  שרן מרים השכל   \n",
       "37196            1  ועדת החינוך, התרבות והספורט  26/07/2021        אלון טל   \n",
       "37197            1  ועדת החינוך, התרבות והספורט  26/07/2021  שרן מרים השכל   \n",
       "37198            1  ועדת החינוך, התרבות והספורט  26/07/2021  סימון דוידסון   \n",
       "\n",
       "       is_chairman   party_name  \\\n",
       "0                1           -1   \n",
       "1                0  ישראל ביתנו   \n",
       "2                1           -1   \n",
       "3                0  ישראל ביתנו   \n",
       "4                1           -1   \n",
       "...            ...          ...   \n",
       "37194            0      יש עתיד   \n",
       "37195            1           -1   \n",
       "37196            0     כחול לבן   \n",
       "37197            1           -1   \n",
       "37198            0      יש עתיד   \n",
       "\n",
       "                                                    text sentiment  \n",
       "0      בוקר טוב לכולם, אני מתכבד לפתוח את הדיון הראשו...     ERROR  \n",
       "1      אדוני היושב-ראש, בוקר טוב, אני חושב שראוי להגד...     ERROR  \n",
       "2      בסדר, אומר לך איך אני רואה את זה באופן כללי וא...     ERROR  \n",
       "3      התקיימו ארבעה דיונים בנושא הזה, בדרך כלל אנחנו...     ERROR  \n",
       "4      היועצת המשפטית של הוועדה תיתן לנו את המסגרת המ...     ERROR  \n",
       "...                                                  ...       ...  \n",
       "37194  גם אני מברך אותך להתמנותך ליו\"ר הוועדה. אני חו...     ERROR  \n",
       "37195                                  תודה רבה. ח\"כ טל.     ERROR  \n",
       "37196  כבוד יושבת הראש אני באמת מצטרף למקהלת המברכים ...     ERROR  \n",
       "37197                 תודה רבה. בבקשה ח\"כ סימון דוידסון.     ERROR  \n",
       "37198  אני רוצה לברך אותך ומאוד שמחתי על מה שאמר רם ש...     ERROR  \n",
       "\n",
       "[37199 rows x 8 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PROTOCOL_PATH)\n",
    "df[\"sentiment\"] = df[\"text\"].apply\n",
    "df[\"sentiment\"] = add_sentiment(model, df[\"text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0        בוקר טוב לכולם, אני מתכבד לפתוח את הדיון הראשו...\\n1        אדוני היושב-ראש, בוקר טוב, אני חושב שראוי להגד...\\n2        בסדר, אומר לך איך אני רואה את זה באופן כללי וא...\\n3        התקיימו ארבעה דיונים בנושא הזה, בדרך כלל אנחנו...\\n4        היועצת המשפטית של הוועדה תיתן לנו את המסגרת המ...\\n                               ...                        \\n37194    גם אני מברך אותך להתמנותך ליו\"ר הוועדה. אני חו...\\n37195                                    תודה רבה. ח\"כ טל.\\n37196    כבוד יושבת הראש אני באמת מצטרף למקהלת המברכים ...\\n37197                   תודה רבה. בבקשה ח\"כ סימון דוידסון.\\n37198    אני רוצה לברך אותך ומאוד שמחתי על מה שאמר רם ש...\\nName: text, Length: 37199, dtype: object'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knesset2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
